{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This workbook accompanies the CURIAL Validation manuscript\n",
    "\n",
    "# This workbook produces summary tables for each study cohort - including demographics,\n",
    "# alongside supplementary tables with summary stats for blood tests, vital signs, blood gasses\n",
    "\n",
    "# Reports level of data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import (YEARLY, DateFormatter,rrulewrapper, RRuleLocator, drange)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#A function to harmonise differently reported ethnic groups/ethnicity\n",
    "def ethnicityHarmoniser(df):\n",
    "    output = df.replace({\n",
    "    \"A\": \"White\", \n",
    "    \"Z\":\"Unknown\", \"Z9\":\"Unknown\", \n",
    "    \"C\":\"White\", \"C3\":\"White\", \"CP\":\"White\", \"CA\":\"White\", \"CB\":\"White\", \"CY\":\"White\", \"CC\":\"White\", \"CW\":\"White\", \"CK\":\"White\",\"CS\":\"White\", \"CN\":\"White\", \"CR\":\"White\", \"CQ\":\"White\", \"CF\":\"White\", \"C2\":\"White\", \"CH\":\"White\", \"CU\":\"White\", \"CHI\":\"White\",\n",
    "    \"J\":\"South Asian\",\n",
    "    \"L\":\"Other\", \"LK\":\"Other\", \"LJ\":\"Other\", \"LA\":\"Other\", \"LH\":\"Other\", \"LE\":\"Other\", \"LD\":\"Other\", \"LG\":\"Other\",\n",
    "    \"H\":\"South Asian\",\n",
    "    \"B\":\"White\",\n",
    "    \"S\":\"Other\", \"SE\":\"Other\", \"SC\":\"Other\", \"SD\":\"Other\", \"SA\":\"Other\",\n",
    "    \"N\":\"Black\", \"NK\":\"Black\", \n",
    "    \"M\":\"Black\",\n",
    "    \"G\":\"Mixed\", \"GF\":\"Mixed\", \"GB\":\"Mixed\",\n",
    "    \"P\":\"Black\", \"PE\":\"Black\", \"PD\":\"Black\", \"PC\":\"Black\", \"PA\":\"Black\",\n",
    "    \"K\":\"South Asian\",\n",
    "    \"D\":\"Mixed\", \"CX\":\"Mixed\", \"GE\":\"Mixed\", \"GD\":\"Mixed\", \"GA\":\"Mixed\",\n",
    "    \"R\":\"Chinese\",\n",
    "    \"F\":\"Mixed\", \n",
    "    \"E\":\"Mixed\",\n",
    "    \"Z\":\"Unknown\",\"ZR\":\"Unknown\",\n",
    "    \"White - British\":\"White\",\n",
    "    \"White- British\":\"White\",\n",
    "    \"Other- Not stated\":\"Unknown\",\n",
    "    \"White- Any other white background\":\"White\",\n",
    "    \"Other - Not Stated\":\"Unknown\",\n",
    "    \"White- Irish\":\"White\",\n",
    "    \"Asian or Asian British - Pakistani\":\"South Asian\",\n",
    "    \"Other- Any other ethnic group\":\"Other\",\n",
    "    \"Black- Any other black background\":\"Black\",\n",
    "    \"White - Any Other White Background\":\"White\",\n",
    "    \"Asian or Asian British - Indian\":\"South Asian\",\n",
    "    \"Asian - Any Other Asian Background\":\"Other\",\n",
    "    \"Other - Not Known\":\"Unknown\",\n",
    "    \"Black or Black British - Caribbean\":\"Black\",\n",
    "    \"Other- Not known\":\"Unknown\",\n",
    "    \"Asian or Asian British -Indian\":\"South Asian\",\n",
    "    \"Other - Any Other Ethnic Group\":\"Other\",\n",
    "    \"Asian or Asian British - Bangladeshi\":\"South Asian\",\n",
    "    \"Mixed - White and Black African\":\"Mixed\",\n",
    "    \"Mixed - White and Black Caribbean\":\"Mixed\",\n",
    "    \"Asian or Asian British -Any other Asian background\":\"Other\",\n",
    "    \"Other-Chinese\":\"Chinese\",\n",
    "    \"1\":\"Unknown\", \"WHT\":\"Unknown\",\"62\":\"Unknown\",\"19\":\"Unknown\",\"87\":\"Unknown\",\n",
    "    })\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training population (pre-pandemic controls)\n",
    "OUHprepandemicControls = pd.read_csv('OUHPrePandemicControls.csv', parse_dates=True)\n",
    "\n",
    "#Apply inclusion criteria\n",
    "OUHprepandemicControls = OUHprepandemicControls[(OUHprepandemicControls.ArrivalDateTime < '2019-12-01') & (OUHprepandemicControls.Age >= 18)]\n",
    "\n",
    "#Process ethnicity values to common format between all datasets\n",
    "OUHprepandemicControls['Ethnicity'] = ethnicityHarmoniser(OUHprepandemicControls['Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training cases cohort\n",
    "OUHw1cases = pd.read_csv('OUHw1ConfirmedCases.csv', parse_dates=True)\n",
    "\n",
    "#Confirm date range\n",
    "OUHw1cases = OUHw1cases[(OUHw1cases.ArrivalDateTime < '2020-07-01') & (OUHw1cases['Covid-19 Positive'] == 1.0)]\n",
    "\n",
    "#Process ethnicity values to common format between all datasets\n",
    "OUHw1cases['Ethnicity'] = ethnicityHarmoniser(OUHw1cases['Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define OUH w2 validation population\n",
    "OUHw2 = pd.read_csv('OUHWave2Attendances.csv', parse_dates=True)\n",
    "\n",
    "#Define second wave (from 10th Oct to end of dataset 6 March)\n",
    "OUHw2 = OUHw2[(OUHw2.ArrivalDateTime >= '2020-10-01')]\n",
    "               \n",
    "#Process ethnicity values to common format between all datasets\n",
    "OUHw2['Ethnicity']=ethnicityHarmoniser(OUHw2['Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define UHB validation Population\n",
    "UHBPopulation = pd.read_csv('UHBValidation.csv',parse_dates=True)\n",
    "\n",
    "#Define population as admitted population (both admitted + ED provided), and from pandemic period\n",
    "UHBPopulation=UHBPopulation[UHBPopulation.ArrivalDateTime > '2019-12-01' ]\n",
    "UHBPopulation = UHBPopulation[(UHBPopulation.Admission == 1.0) | (UHBPopulation.ICU == 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and import Portsmouth Population\n",
    "PortsmouthPopulation=pd.read_csv('PUHValidation.csv',parse_dates=True)\n",
    "\n",
    "#Set inclusion criteria - population is admitted population and excluding invalid results\n",
    "PortsmouthPopulation = PortsmouthPopulation[~(PortsmouthPopulation['Covid-19 Positive'].isna())]\n",
    "PortsmouthPopulation = PortsmouthPopulation[(df.Admission == 1.0) | (PortsmouthPopulation.ICU == 1.0)]\n",
    "\n",
    "PortsmouthPopulation['Ethnicity']=ethnicityHarmoniser(PortsmouthPopulation['Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and import Bedfordshire Hospitals NHS Trust Popilation\n",
    "BedfordshirePopulation = pd.read_csv('BHValidation.csv',parse_dates=True)\n",
    "\n",
    "#Set inclusion criteria - population is admitted population and excluding invalid results\n",
    "BedfordshirePopulation = BedfordshirePopulation[(BedfordshirePopulation.Admission == 1.0) | (BedfordshirePopulation.ICU == 1.0)]\n",
    "BedfordshirePopulation = BedfordshirePopulation[~(BedfordshirePopulation['Covid-19 Positive'].isna())]\n",
    "\n",
    "#Process ethnicity values to common format between all datasets\n",
    "BedfordshirePopulation['Ethnicity']=ethnicityHarmoniser(BedfordshirePopulation['Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define OUH w2 LFD-validation population\n",
    "#File contains only tested participants\n",
    "OUHw2LFD = pd.read_csv('OUHWave2WithLFDs.csv', parse_dates=True)\n",
    "\n",
    "#Enforce inclusion criteria, restricting to patients who had an LFD test, excluding invalid results, and patients who were admitted\n",
    "OUHw2LFD = OUHw2LFD[(OUHw2LFD.Lateral_flow_result=='Positive') | (OUHw2LFD.Lateral_flow_result=='Negative')]\n",
    "OUHw2LFD = OUHw2LFD[OUHw2LFD.Admission == 1]\n",
    "\n",
    "#Process ethnicity values to common format between all datasets\n",
    "OUHw2LFD['Ethnicity']=ethnicityHarmoniser(OUHw2LFD['Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curial_Rapide Prospective Validation Study\n",
    "CRValidation = pd.read_csv(\"CURIAL-OLOServiceEvaluation.csv\", \n",
    "                         parse_dates=['ArrivalDateTime', 'OLOMachineDateTime', 'VitalsDateTime', 'PCRDateTime', 'LFDDateTime', 'LabDateTime', 'DTADateTime', 'DischargeDateTime', 'ArrivalDate', 'ArrivalTime'],\n",
    "                         infer_datetime_format=True)\n",
    "\n",
    "#Process ethnicity values to common format between all datasets\n",
    "CRValidation['Ethnicity']=ethnicityHarmoniser(CRValidation['Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Summary Table\n",
    "summarytable = pd.DataFrame(index=[\"n Total\",\n",
    "                                     \"n Covid-19\", \n",
    "                                     \"Sex M (%)\", \n",
    "                                     \"Sex F (%)\",\n",
    "                                    \"Age (IQR)\",\n",
    "                                     \"LFD (% positive)\", \n",
    "                                     \"Ethnicity: White\", \n",
    "                                     \"Ethnicity: Not stated\", \n",
    "                                     \"Ethnicity: South Asian\",\n",
    "                                     \"Ethnicity: Chinese\",\n",
    "                                     \"Ethnicity: Black\", \n",
    "                                     \"Ethnicity: Other\", \n",
    "                                     \"Ethnicity: Mixed\", \n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summarytable for pre-pandemic training\n",
    "df = OUHprepandemicControls\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Gender'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "summarytable['Training: OUH pre-pandemic cohort'] = [len(df), \n",
    "                                   df['Covid-19 Positive'].sum(), \n",
    "                                   genderSummaryStats['M']+ \" (\" +str(((df['Gender'].value_counts()['M']/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats['F']+ \" (\" +str(((df['Gender'].value_counts()['F']/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   np.NaN,\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Chinese']+ \" (\" +str(((df['Ethnicity'].value_counts()['Chinese']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summarytable for wave 1 cases training\n",
    "df = OUHw1cases\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Gender'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "summarytable['Training: OUH cases cohort'] = [len(df), \n",
    "                                   df['Covid-19 Positive'].sum(), \n",
    "                                   genderSummaryStats['M']+ \" (\" +str(((df['Gender'].value_counts()['M']/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats['F']+ \" (\" +str(((df['Gender'].value_counts()['F']/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   np.NaN,\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   \"0 (0)\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summarytable for FULL OUH W2 VALIDATION\n",
    "df = OUHw2\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Gender'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "summarytable['Validation: OUH w2 Validation'] = [len(df),\n",
    "                                   df['Covid-19 Positive'].sum(), \n",
    "                                   genderSummaryStats['M']+ \" (\" +str(((df['Gender'].value_counts()['M']/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats['F']+ \" (\" +str(((df['Gender'].value_counts()['F']/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   np.NaN,\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Chinese']+ \" (\" +str(((df['Ethnicity'].value_counts()['Chinese']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summarytable for Validvalue_countsPortsmouth\n",
    "df = PortsmouthPopulation\n",
    "\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Gender'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "\n",
    "#NB: Ajdusted for n=0 Chinese population in this cohort\n",
    "summarytable['Validation: Portsmouth University Hospitals'] = [len(df), \n",
    "                                   df['Covid-19 Positive'].sum(), \n",
    "                                   genderSummaryStats[0]+ \" (\" +str(((df['Gender'].value_counts()[0]/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats[1]+ \" (\" +str(((df['Gender'].value_counts()[1]/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   np.NaN,\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Chinese']+ \" (\" +str(((df['Ethnicity'].value_counts()['Chinese']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summarytable for Validation: UHB\n",
    "df = UHBPopulation\n",
    "\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Gender'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "summarytable['Validation: UHB'] = [len(df), \n",
    "                                   df['Covid-19 Positive'].sum(), \n",
    "                                   genderSummaryStats['M']+ \" (\" +str(((df['Gender'].value_counts()['M']/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats['F']+ \" (\" +str(((df['Gender'].value_counts()['F']/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   np.NaN,\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Chinese']+ \" (\" +str(((df['Ethnicity'].value_counts()['Chinese']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summarytable for validation: Bedford\n",
    "df = BedfordshirePopulation\n",
    "\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Gender'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "\n",
    "#NB: Ajdusted for n=0 Chinese population in this cohort\n",
    "summarytable['Validation: Bedfordshire Hospitals'] = [len(df), \n",
    "                                   df['Covid-19 Positive'].sum(), \n",
    "                                   genderSummaryStats[0]+ \" (\" +str(((df['Gender'].value_counts()[0]/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats[1]+ \" (\" +str(((df['Gender'].value_counts()[1]/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   np.NaN,\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   \"0 (0)\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summarytable for Validation-LFD: OUH\n",
    "df = OUHw2LFD\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Gender'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "summarytable['Validation-LFD: OUH LFD Comparison'] = [len(df),\n",
    "                                   df['Covid-19 Positive'].sum(), \n",
    "                                   genderSummaryStats['M']+ \" (\" +str(((df['Gender'].value_counts()['M']/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats['F']+ \" (\" +str(((df['Gender'].value_counts()['F']/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   str(df['Lateral_flow_result'].value_counts()['Positive'])+ \" (\" +str(((df['Lateral_flow_result'].value_counts()['Positive']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Chinese']+ \" (\" +str(((df['Ethnicity'].value_counts()['Chinese']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row to summry table for C-R/OLO service evaluation\n",
    "df = CRValidation\n",
    "dfSummaryStats = df.describe()['Age'].round(2).map(str)\n",
    "genderSummaryStats = df['Sex'].value_counts().map(str)\n",
    "ethnicityNumbers = df['Ethnicity'].value_counts().map(str)\n",
    "summarytable['Real-World Validation: CURIAL-Rapide'] = [len(df),\n",
    "                                   df['PCRResult'].value_counts()['Positive'], \n",
    "                                   genderSummaryStats['man']+ \" (\" +str(((df['Sex'].value_counts()['man']/len(df))*100).round(2))+ \")\",\n",
    "                                   genderSummaryStats['woman']+ \" (\" +str(((df['Sex'].value_counts()['woman']/len(df))*100).round(2))+ \")\",\n",
    "                                   dfSummaryStats['50%'] + \" (\" + dfSummaryStats['25%'] + \"-\"+ dfSummaryStats['75%'] + \")\",\n",
    "                                   str(df['LFDResult'].value_counts()['POSITIVE'])+ \" (\" +str(((df['LFDResult'].value_counts()['POSITIVE']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['White']+ \" (\" +str(((df['Ethnicity'].value_counts()['White']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Unknown']+ \" (\" +str(((df['Ethnicity'].value_counts()['Unknown']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['South Asian']+ \" (\" +str(((df['Ethnicity'].value_counts()['South Asian']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Chinese']+ \" (\" +str(((df['Ethnicity'].value_counts()['Chinese']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Black']+ \" (\" +str(((df['Ethnicity'].value_counts()['Black']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Other']+ \" (\" +str(((df['Ethnicity'].value_counts()['Other']/len(df))*100).round(2))+ \")\",\n",
    "                                   ethnicityNumbers['Mixed']+ \" (\" +str(((df['Ethnicity'].value_counts()['Mixed']/len(df))*100).round(2))+ \")\",\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Now create a summary table with each of the key features #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate ordered indicies for tables\n",
    "bloodsIndex = UHBPopulation.loc[:,'Blood_Test HAEMOGLOBIN':'Blood_Test CRP'].columns\n",
    "vitalsIndex = UHBPopulation.columns[UHBPopulation.columns.str.startswith('Vital_Sign')]\n",
    "gasIndex = UHBPopulation.columns[UHBPopulation.columns.str.startswith('Blood_Gas')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tables with ordered indicies\n",
    "BloodParams = pd.DataFrame(index=bloodsIndex)\n",
    "VitalsParams = pd.DataFrame(index=vitalsIndex)\n",
    "GasParams = pd.DataFrame(index=gasIndex)\n",
    "\n",
    "#Now make missing data tables\n",
    "BloodsCompleteness = pd.DataFrame(index=bloodsIndex)\n",
    "VitalsCompleteness = pd.DataFrame(index=vitalsIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in OUH pre-pandemic training summary stats\n",
    "OUHprepandemicControls = OUHprepandemicControls[(OUHprepandemicControls['ArrivalDateTime'] < '2019-12-01')]\n",
    "summaryBloodsMetrics = OUHprepandemicControls[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = OUHprepandemicControls[vitalsIndex].describe().T.round(1)\n",
    "summaryGasMetrics = OUHprepandemicControls[gasIndex].describe().T.round(2)\n",
    "BloodParams['OUH Training: Prepandemic median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['OUH Training: Prepandemic median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "GasParams['OUH Training: Prepandemic median (IQR)'] = summaryGasMetrics['50%'].map(str) + \" (\" + summaryGasMetrics['25%'].map(str) + \"-\"+ summaryGasMetrics['75%'].map(str) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in OUH pandemic training summary stats\n",
    "OUHw1cases = OUHw1cases[(OUHw1cases['Covid-19 Positive'] == 1.0)]\n",
    "summaryBloodsMetrics = OUHw1cases[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = OUHw1cases[vitalsIndex].describe().T.round(1)\n",
    "summaryGasMetrics = OUHw1cases[gasIndex].describe().T.round(2)\n",
    "BloodParams['OUH Training: Cases (w1) median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['OUH Training: Cases (w1) median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "GasParams['OUH Training: Cases (w1) median (IQR)'] = summaryGasMetrics['50%'].map(str) + \" (\" + summaryGasMetrics['25%'].map(str) + \"-\"+ summaryGasMetrics['75%'].map(str) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in OUH w2 Summary Stats\n",
    "summaryBloodsMetrics = OUHw2[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = OUHw2[vitalsIndex].describe().T.round(1)\n",
    "summaryGasMetrics = OUHw2[gasIndex].describe().T.round(2)\n",
    "BloodParams['OUHw2 median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['OUHw2 median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "GasParams['OUHw2 median (IQR)'] = summaryGasMetrics['50%'].map(str) + \" (\" + summaryGasMetrics['25%'].map(str) + \"-\"+ summaryGasMetrics['75%'].map(str) + \")\"\n",
    "\n",
    "completenessFor = OUHw2\n",
    "BloodsCompleteness['OUHw2Validation'] = completenessFor[bloodsIndex].count().map(str)+ \"/\" + str(completenessFor[bloodsIndex].shape[0]) + \" (\" +((completenessFor[bloodsIndex].count().values / completenessFor[bloodsIndex].shape[0])*100).round(1).astype(str) + \"%)\"\n",
    "VitalsCompleteness['OUHw2Validation'] = completenessFor[vitalsIndex].count().map(str)+ \"/\" + str(completenessFor[vitalsIndex].shape[0]) + \" (\" +((completenessFor[vitalsIndex].count().values / completenessFor[vitalsIndex].shape[0])*100).round(1).astype(str) + \"%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in UHB Summary Stats\n",
    "summaryBloodsMetrics = UHBPopulation[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = UHBPopulation[vitalsIndex].describe().T.round(1)\n",
    "summaryGasMetrics = UHBPopulation[gasIndex].describe().T.round(2)\n",
    "BloodParams['UHB median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['UHB median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "GasParams['UHB median (IQR)'] = summaryGasMetrics['50%'].map(str) + \" (\" + summaryGasMetrics['25%'].map(str) + \"-\"+ summaryGasMetrics['75%'].map(str) + \")\"\n",
    "\n",
    "completenessFor = UHBPopulation\n",
    "BloodsCompleteness['UHB'] = completenessFor[bloodsIndex].count().map(str)+ \"/\" + str(completenessFor[bloodsIndex].shape[0]) + \" (\" +((completenessFor[bloodsIndex].count().values / completenessFor[bloodsIndex].shape[0])*100).round(1).astype(str) + \"%)\"\n",
    "VitalsCompleteness['UHB'] = completenessFor[vitalsIndex].count().map(str)+ \"/\" + str(completenessFor[vitalsIndex].shape[0]) + \" (\" +((completenessFor[vitalsIndex].count().values / completenessFor[vitalsIndex].shape[0])*100).round(1).astype(str) + \"%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in Portsmouth Summary Stats\n",
    "summaryBloodsMetrics = PortsmouthPopulation[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = PortsmouthPopulation[vitalsIndex].describe().T.round(1)\n",
    "#summaryGasMetrics = PortsmouthPopulation[gasIndex].describe().T.round(2)\n",
    "BloodParams['Portsmouth median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['Portsmouth median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "#GasParams['Portsmouth Mean (IQR)'] = summaryGasMetrics['mean'].map(str) + \" (\" + summaryGasMetrics['25%'].map(str) + \"-\"+ summaryGasMetrics['75%'].map(str) + \")\"\n",
    "\n",
    "completenessFor = PortsmouthPopulation\n",
    "BloodsCompleteness['PUH'] = completenessFor[bloodsIndex].count().map(str)+ \"/\" + str(completenessFor[bloodsIndex].shape[0]) + \" (\" +((completenessFor[bloodsIndex].count().values / completenessFor[bloodsIndex].shape[0])*100).round(1).astype(str) + \"%)\"\n",
    "VitalsCompleteness['PUH'] = completenessFor[vitalsIndex].count().map(str)+ \"/\" + str(completenessFor[vitalsIndex].shape[0]) + \" (\" +((completenessFor[vitalsIndex].count().values / completenessFor[vitalsIndex].shape[0])*100).round(1).astype(str) + \"%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in Bedford Summary Stats\n",
    "summaryBloodsMetrics = BedfordshirePopulation[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = BedfordshirePopulation[vitalsIndex].describe().T.round(1)\n",
    "summaryGasMetrics = BedfordshirePopulation[gasIndex].describe().T.round(2)\n",
    "BloodParams['Bedfordshire median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['Bedfordshire median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "GasParams['Bedfordshire median (IQR)'] = summaryGasMetrics['50%'].map(str) + \" (\" + summaryGasMetrics['25%'].map(str) + \"-\"+ summaryGasMetrics['75%'].map(str) + \")\"\n",
    "\n",
    "\n",
    "completenessFor = BedfordshirePopulation\n",
    "BloodsCompleteness['Bedford'] = completenessFor[bloodsIndex].count().map(str)+ \"/\" + str(completenessFor[bloodsIndex].shape[0]) + \" (\" +((completenessFor[bloodsIndex].count().values / completenessFor[bloodsIndex].shape[0])*100).round(1).astype(str) + \"%)\"\n",
    "VitalsCompleteness['Bedford'] = completenessFor[vitalsIndex].count().map(str)+ \"/\" + str(completenessFor[vitalsIndex].shape[0]) + \" (\" +((completenessFor[vitalsIndex].count().values / completenessFor[vitalsIndex].shape[0])*100).round(1).astype(str) + \"%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in OUH LFT Summary Stats\n",
    "summaryBloodsMetrics = OUHw2LFD[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = OUHw2LFD[vitalsIndex].describe().T.round(1)\n",
    "summaryGasMetrics = OUHw2LFD[gasIndex].describe().T.round(2)\n",
    "BloodParams['OUHw2 LFT median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['OUHw2 LFT median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "GasParams['OUHw2 LFT median (IQR)'] = summaryGasMetrics['50%'].map(str) + \" (\" + summaryGasMetrics['25%'].map(str) + \"-\"+ summaryGasMetrics['75%'].map(str) + \")\"\n",
    "\n",
    "completenessFor = OUHw2LFD\n",
    "BloodsCompleteness['OUHw2 LFT'] = completenessFor[bloodsIndex].count().map(str)+ \"/\" + str(completenessFor[bloodsIndex].shape[0]) + \" (\" +((completenessFor[bloodsIndex].count().values / completenessFor[bloodsIndex].shape[0])*100).round(1).astype(str) + \"%)\"\n",
    "VitalsCompleteness['OUHw2 LFT'] = completenessFor[vitalsIndex].count().map(str)+ \"/\" + str(completenessFor[vitalsIndex].shape[0]) + \" (\" +((completenessFor[vitalsIndex].count().values / completenessFor[vitalsIndex].shape[0])*100).round(1).astype(str) + \"%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in CURIAL-Rapide Summary Stats\n",
    "#Identify C-R specific bloods, and create an empty df with the non-FBC bloods\n",
    "missingcols = bloodsIndex[~bloodsIndex.isin(CRValidation.columns)]\n",
    "missingColsDf = pd.DataFrame(columns=missingcols)\n",
    "\n",
    "#Now add dummy rows with NaNs to the dataset for non-FBC bloods to populate full table rows correctly\n",
    "fullBloods = pd.concat([CRValidation, missingColsDf])\n",
    "\n",
    "summaryBloodsMetrics = fullBloods[bloodsIndex].describe().T.round(2)\n",
    "summaryVitalsMetrics = CRValidation[vitalsIndex].describe().T.round(1)\n",
    "BloodParams['CURIAL-Rapide median (IQR)'] = summaryBloodsMetrics['50%'].map(str) + \" (\" + summaryBloodsMetrics['25%'].map(str) + \"-\"+ summaryBloodsMetrics['75%'].map(str) + \")\"\n",
    "VitalsParams['CURIAL-Rapide median (IQR)'] = summaryVitalsMetrics['50%'].map(str) + \" (\" + summaryVitalsMetrics['25%'].map(str) + \"-\"+ summaryVitalsMetrics['75%'].map(str) + \")\"\n",
    "\n",
    "completenessFor = CRValidation\n",
    "BloodsCompleteness['C-R Evaluation'] = fullBloods[bloodsIndex].count().map(str)+ \"/\" + str(fullBloods[bloodsIndex].shape[0]) + \" (\" +((fullBloods[bloodsIndex].count().values / fullBloods[bloodsIndex].shape[0])*100).round(1).astype(str) + \"%)\"\n",
    "VitalsCompleteness['C-R Evaluation'] = completenessFor[vitalsIndex].count().map(str)+ \"/\" + str(completenessFor[vitalsIndex].shape[0]) + \" (\" +((completenessFor[vitalsIndex].count().values / completenessFor[vitalsIndex].shape[0])*100).round(1).astype(str) + \"%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BloodParams\n",
    "#BloodParams.to_csv(\"SI S2 Blood Params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print tables of missing data\n",
    "BloodsCompleteness\n",
    "#BloodsCompleteness.to_csv(\"SI Bloods Completeness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VitalsCompleteness\n",
    "#VitalsCompleteness.to_csv(\"SI Vitals Completeness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VitalsParams\n",
    "#VitalsParams.to_csv(\"SI S2 Vitals Params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GasParams\n",
    "#GasParams.to_csv(\"SI S2 Gas Params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarytable.round(1).to_csv(\"04 Summary Table 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing ages between populations\n",
    "from scipy import stats\n",
    "\n",
    "#Portsmouth vs Bham\n",
    "stats.kruskal(PortsmouthPopulation.Age, UHBPopulation.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bedford vs Bham\n",
    "stats.kruskal(UHBPopulation.Age, BedfordshirePopulation.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portsmouth vs Bedford\n",
    "stats.kruskal(PortsmouthPopulation.Age, BedfordshirePopulation.Age)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
